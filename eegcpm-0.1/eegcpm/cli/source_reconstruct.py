"""CLI command for source reconstruction."""

from pathlib import Path
from typing import List, Optional
import mne

from eegcpm.core.config import SourceConfig
from eegcpm.core.task_config import TaskConfig
from eegcpm.core.paths import EEGCPMPaths
from eegcpm.modules.source import SourceReconstructionModule
from eegcpm.data.event_mapping import get_event_mapping_for_run, translate_event_codes


def source_reconstruct_command(args):
    """
    Run source reconstruction on epoched data.

    Parameters
    ----------
    args : argparse.Namespace
        Parsed command-line arguments with:
        - project: Path - Project root directory
        - config: Path - Source reconstruction config file
        - preprocessing: str - Preprocessing pipeline variant
        - task: str - Task name
        - subjects: List[str], optional - Specific subjects to process
        - sessions: List[str], optional - Specific sessions to process
    """
    project_root = Path(args.project)
    config_path = Path(args.config)

    print(f"\n{'='*60}")
    print("EEGCPM Source Reconstruction")
    print(f"{'='*60}\n")

    # Load configuration
    print(f"Loading config: {config_path}")
    source_config = SourceConfig.from_yaml(config_path)
    print(f"   Method: {source_config.method}")
    print(f"   Variant: {source_config.variant}")
    print(f"   Parcellation: {source_config.parcellation}")

    # Initialize paths
    paths = EEGCPMPaths(project_root)

    # Get dependencies - CLI args take precedence over config
    preprocessing = getattr(args, 'preprocessing', None)
    task = getattr(args, 'task', None)

    # Fall back to config if not specified on CLI
    if not preprocessing and source_config.depends_on:
        preprocessing = source_config.depends_on.get('preprocessing')
    if not task and source_config.depends_on:
        task = source_config.depends_on.get('task')

    epochs_variant = source_config.depends_on.get('epochs') if source_config.depends_on else None

    if not all([preprocessing, task]):
        raise ValueError("Must specify --preprocessing and --task (or include in config)")

    print(f"\nüìä Dependencies:")
    print(f"   Preprocessing: {preprocessing}")
    print(f"   Task: {task}")
    print(f"   Epochs: {epochs_variant or 'N/A (will use raw data)'}")

    # Load task config if available (for condition grouping)
    task_config = None
    task_config_name = getattr(args, 'task_config', None)

    # Determine which task config to use
    if task_config_name == "none":
        print(f"   ‚ö†Ô∏è  Task config disabled (--task-config none)")
        print(f"   Will process each event separately (no grouping by condition)")
    else:
        # Use specified config or auto-detect by matching task_name field
        if task_config_name is None:
            # Auto-detect: find configs where task_name matches
            print(f"   üìã Auto-detecting task configs for task: {task}")
            task_configs_dir = paths.get_configs_dir("tasks")
            matching_configs = []

            if task_configs_dir.exists():
                for config_file in task_configs_dir.glob("*.yaml"):
                    try:
                        import yaml
                        with open(config_file) as f:
                            cfg = yaml.safe_load(f)

                        # Check if task_name field matches
                        if cfg.get('task_name') == task:
                            matching_configs.append(config_file)
                    except Exception:
                        continue

            if matching_configs:
                # Try exact filename match first
                exact_match = [c for c in matching_configs if c.stem == task]
                if exact_match:
                    task_config_path = exact_match[0]
                    print(f"   ‚úì Found exact match: {task_config_path.name}")
                else:
                    # Use first alphabetically
                    matching_configs.sort(key=lambda x: x.stem)
                    task_config_path = matching_configs[0]
                    print(f"   ‚úì Using first match: {task_config_path.name}")

                if len(matching_configs) > 1:
                    print(f"   ‚ÑπÔ∏è  Found {len(matching_configs)} matching configs for task '{task}'")
                    for cfg in matching_configs:
                        print(f"      - {cfg.name}")
            else:
                print(f"   ‚ö†Ô∏è  No task configs found with task_name='{task}'")
                print(f"   Will process each event separately (no grouping by condition)")
                task_config_path = None
        else:
            # Specific config requested
            print(f"   üìã Using specified task config: {task_config_name}.yaml")
            task_config_path = paths.get_configs_dir("tasks") / f"{task_config_name}.yaml"

        # Load the selected config
        if task_config_path and task_config_path.exists():
            try:
                task_config = TaskConfig.from_yaml(task_config_path)

                # Validate task_name matches
                if task_config.task_name != task:
                    print(f"   ‚ö†Ô∏è  Warning: Config task_name '{task_config.task_name}' doesn't match dependency task '{task}'")
                    print(f"   Proceeding anyway (manual override)")

                print(f"   ‚úì Loaded task config: {task_config_path.name}")
                print(f"   Conditions: {[c.name for c in task_config.conditions]}")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Could not load task config: {e}")
                print(f"   Will process each event separately")
                task_config = None
        elif task_config_path:
            print(f"   ‚ö†Ô∏è  Task config not found: {task_config_path}")
            print(f"   Will process each event separately (no grouping by condition)")

    # Get epochs directory (root, without subject/session filters)
    epochs_dir = paths.derivatives_root / "epochs" / preprocessing / task

    if not epochs_dir.exists():
        raise FileNotFoundError(f"Epochs directory not found: {epochs_dir}")

    # Find subjects to process
    subject_dirs = list(epochs_dir.glob("sub-*"))
    if not subject_dirs:
        raise FileNotFoundError(f"No subjects found in: {epochs_dir}")

    # Filter subjects if specified
    if args.subjects:
        subject_dirs = [
            d for d in subject_dirs
            if d.name.replace("sub-", "") in args.subjects
        ]

    print(f"\nüë• Found {len(subject_dirs)} subjects to process")

    # Process each subject
    n_success = 0
    n_failed = 0
    failed_subjects = []

    for subject_dir in subject_dirs:
        subject_id = subject_dir.name.replace("sub-", "")

        # Find sessions
        session_dirs = list(subject_dir.glob("ses-*"))
        if not session_dirs:
            # No session subdirectory, look for epoch files directly
            session_dirs = [subject_dir]

        for session_dir in session_dirs:
            if session_dir.name.startswith("ses-"):
                session_id = session_dir.name.replace("ses-", "")
            else:
                session_id = "01"

            # Filter sessions if specified
            if args.sessions and session_id not in args.sessions:
                continue

            print(f"\nüîÑ Processing: sub-{subject_id}, ses-{session_id}")

            # Find epoch file
            epoch_files = list(session_dir.glob("*_epo.fif"))
            if not epoch_files:
                print(f"   ‚ö†Ô∏è  No epoch file found, skipping")
                continue

            epoch_file = epoch_files[0]
            print(f"   üìÇ Loading epochs: {epoch_file.name}")

            try:
                # Load epochs
                epochs = mne.read_epochs(epoch_file, preload=True, verbose=False)
                print(f"   ‚úì Loaded {len(epochs)} epochs")

                # Translate task config event codes to match epochs
                task_config_translated = None
                if task_config:
                    # Get event mapping from BIDS
                    # Try to find events.tsv - check different run numbers
                    event_mapping = {}
                    for run_num in ["1", "01", "2", "02", "3", "03"]:
                        event_mapping = get_event_mapping_for_run(
                            bids_root=paths.bids_root,
                            subject=subject_id,
                            session=session_id,
                            task=task,
                            run=run_num
                        )
                        if event_mapping:
                            print(f"   üìã Using event mapping from run-{run_num}")
                            break

                    if event_mapping:
                        # Create translated version of task config
                        task_config_dict = task_config.model_dump()
                        for condition in task_config_dict['conditions']:
                            original_codes = condition['event_codes']
                            translated_codes = translate_event_codes(original_codes, event_mapping)
                            condition['event_codes'] = translated_codes
                            print(f"   üîÑ Condition '{condition['name']}': {original_codes} ‚Üí {translated_codes}")

                        task_config_translated = task_config_dict
                    else:
                        print(f"   ‚ö†Ô∏è  No event mapping found - using task config as-is")
                        task_config_translated = task_config.model_dump() if task_config else None
                else:
                    task_config_translated = None

                # Get output directory using stage-first paths
                output_dir = paths.get_source_dir(
                    preprocessing=preprocessing,
                    task=task,
                    variant=source_config.variant,
                    subject=subject_id,
                    session=session_id
                )

                # Create subject object (simple namespace)
                from types import SimpleNamespace
                subject = SimpleNamespace(id=subject_id, session=session_id)

                # Run source reconstruction
                module = SourceReconstructionModule(
                    config=source_config.model_dump(),
                    output_dir=output_dir,
                    task_config=task_config_translated
                )
                result = module.process(epochs, subject=subject)

                if result.success:
                    print(f"   ‚úÖ Success!")
                    print(f"   üìÅ Output: {output_dir}")
                    if result.output_files:
                        print(f"   üìÑ Files: {len(result.output_files)}")
                        for f in result.output_files:
                            print(f"      - {f.name}")
                    n_success += 1
                else:
                    print(f"   ‚ùå Failed: {result.errors}")
                    n_failed += 1
                    failed_subjects.append(f"{subject_id}/ses-{session_id}")

                if result.warnings:
                    for warning in result.warnings:
                        print(f"   ‚ö†Ô∏è  {warning}")

            except Exception as e:
                print(f"   ‚ùå Error: {str(e)}")
                n_failed += 1
                failed_subjects.append(f"{subject_id}/ses-{session_id}")

    # Summary
    print(f"\n{'='*60}")
    print("Summary")
    print(f"{'='*60}")
    print(f"‚úÖ Successful: {n_success}")
    print(f"‚ùå Failed: {n_failed}")

    if failed_subjects:
        print(f"\nFailed subjects:")
        for sub in failed_subjects:
            print(f"  - {sub}")

    print()
